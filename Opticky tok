
import sys
sys.path.append(r"/home/smejo/Desktop/opencv-3.1.0/samples/python")
import numpy as np
import cv2
import video
from common import  draw_str
from collections import deque

# parametre pre opt. tok
lk_params = dict( winSize  = (15, 15),
                  maxLevel = 2,
                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))
# parametre pre GoodFeaturesToTrack
feature_params = dict( maxCorners = 500,
                       qualityLevel = 0.3,
                       minDistance = 7,
                       blockSize = 7 )

class App:
    def __init__(self, video_src):
        self.track_len = 10
        self.detect_interval = 5
        self.tracks = []
        self.cam = video.create_capture(video_src)
        self.frame_idx = 0
        

    
            
        # funkcia na detekciu smeru optickeho toku , vytvori pole pre kazdy zachyteny bod , vypocita sa arit. priemer na urcenie smeru
    def detect_direction(self,tracks):
        xy_mov=np.array([t[-1][0]-t[0][0] for t in tracks])
        xy_mov1 = np.array([t[-1][1] - t[0][1] for t in tracks])
        # print([t[-1][1] for t in tracks])
        # print([t[0][0] for t in tracks])
        xy_mean = np.mean(xy_mov[np.abs(xy_mov)>70])
        xy_mean1 = np.mean(xy_mov1[np.abs(xy_mov1) > 70])
        
            
        #print xy_mean
        if xy_mean < -20:
            print("left")
            
        if xy_mean > 20:
            print("right")
            
            
        if xy_mean1 < 20: 
            print("up")
        if xy_mean1 > -20:
            print("down")

    def run(self):
        while True:
            # zachytime prvy frame
            ret, frame = self.cam.read()
            frame = frame[:,::-1,:]
            # prevedieme frame do sedej
            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            vis = frame.copy()

            if len(self.tracks) > 0:
                # update premennych za za kazdym cyklom
                img0, img1 = self.prev_gray, frame_gray
                # vytvorenie pola, kde uchovavame hnodnotu kazdej znamej suradnice pre kazdy bod
                p0 = np.float32([tr[-1] for tr in self.tracks]).reshape(-1, 1, 2)
                # vypocitame opticky tok, 2x - backtracking
                p1, st, err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)
                p0r, st, err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)
                d = abs(p0-p0r).reshape(-1, 2).max(-1)
                good = d < 1
                # vytvorenie listu pre uchovavavnie suradnic
                new_tracks = []
                for tr, (x, y), good_flag in zip(self.tracks, p1.reshape(-1, 2), good):
                    if not good_flag:
                        continue
                    # pridame suradnice do listu pre kazdy zachyteny bod
                    tr.append((x, y))
                    new_tracks.append(tr)
                    # zachytene body zobrazime 
                    cv2.circle(vis, (x, y), 2, (0, 255, 0), -1)
                self.tracks = new_tracks
                # zobrazime trajektoriu vsetkym zachytenych bodov
                cv2.polylines(vis, [np.int32(tr) for tr in self.tracks], False, (0, 255, 0))
                # vypis aktualne zachytenych bodov
                draw_str(vis, (20, 20), 'track count: %d' % len(self.tracks))
                self.gesture = self.detect_direction(self.tracks)
                # print(self.tracks[0][0][0])
                # print(self.tracks[1][0][0])
                
                # tymto zabezpecime to, uz nebudeme hladat dalsie body znova pri aktualne zachytenych bodoch 
            if self.frame_idx % self.detect_interval == 0:
                mask = np.zeros_like(frame_gray)
                mask[:] = 255
                for x, y in [np.int32(tr[-1]) for tr in self.tracks]:
                    cv2.circle(mask, (x, y), 5, 0, -1)
                    # najdeme nejake nove body na zachytenie
                p = cv2.goodFeaturesToTrack(frame_gray, mask = mask, **feature_params)
                if p is not None:
                    for x, y in np.float32(p).reshape(-1, 2):
                        self.tracks.append(deque([(x, y)],self.track_len))

            # prejdeme na dalsi obrazok
            self.frame_idx += 1
            self.prev_gray = frame_gray
            cv2.imshow('lk_track', vis)

            ch =  cv2.waitKey(1)
            if (ch == 27):            
                break

def main():
    import sys
    try:
        video_src = sys.argv[1]
    except:
        video_src = 1 # externa kamera

    App(video_src).run()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
